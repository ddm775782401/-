{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练集80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random,os,cv2,glob\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "import pywt\n",
    "from sklearn.svm import  SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from cv2 import cv2\n",
    "\n",
    "def loadImageSet(folder=u'face', sampleCount=5): \n",
    "    trainData = []; testData = [];yTrain2=[];yTest2=[]\n",
    "    for k in range(40):\n",
    "        yTrain1 = [k]\n",
    "        yTest1 =[k]\n",
    "        folder2 = os.path.join(folder, 's%d' % (k+1))\n",
    "        data = [ cv2.imread(d,0) for d in glob.glob(os.path.join(folder2, '*.bmp'))]\n",
    "\n",
    "        # sample=[3,4,5,6]\n",
    "        sample=[2,3,4,5,6,7,8,9]\n",
    "        trainData.extend([data[i].ravel() for i in range(10) if i in sample])\n",
    "        testData.extend([data[i].ravel() for i in range(10) if i not in sample])\n",
    "\n",
    "  \n",
    "        yTrain = np.matrix(yTrain1)\n",
    "        yTrain= np.tile(yTrain1,8)\n",
    "        yTest=np.tile(yTest1,2)\n",
    "        yTrain2.extend(yTrain)\n",
    "        yTest2.extend(yTest)\n",
    "    return np.array(trainData),  np.array(yTrain2), np.array(testData), np.array(yTest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain_, yTrain, xTest_, yTest = loadImageSet()\n",
    "pca=PCA(n_components=0.9)\n",
    "xTrain_pca=pca.fit_transform(xTrain_)# 把原始训练集映射到主成分组成的子空间中\n",
    "xTest_pca=pca.transform(xTest_)# 把原始测试集映射到主成分组成的子空间中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((320, 98), (320,))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain_pca.shape,yTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(xTrain_pca)\n",
    "x_test=torch.from_numpy(xTest_pca)\n",
    "y_train=torch.from_numpy(yTrain)\n",
    "y_test=torch.from_numpy(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "D:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "D:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "x_train= torch.tensor(x_train, dtype=torch.float32)\n",
    "x_test= torch.tensor(x_test, dtype=torch.float32)\n",
    "y_train= torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test= torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------      构建数据集      ------\n",
      "------      搭建网络      ------\n",
      "网络结构为： Net(\n",
      "  (layer1): Sequential(\n",
      "    (0): Linear(in_features=98, out_features=512, bias=True)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer4): Linear(in_features=128, out_features=40, bias=True)\n",
      ")\n",
      "------      启动训练      ------\n",
      "3.719383716583252\n",
      "1.3317019939422607\n",
      "0.6373937726020813\n",
      "0.3493385314941406\n",
      "0.22174346446990967\n",
      "0.15639720857143402\n",
      "0.1184602826833725\n",
      "0.09421464800834656\n",
      "0.07766993343830109\n",
      "0.06575452536344528\n",
      "训练结束\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import math\n",
    "%matplotlib inline\n",
    "print('------      构建数据集      ------')\n",
    "\n",
    "# Variable是将tensor封装了下，用于自动求导使用\n",
    "x, y = Variable(x_train), Variable(y_train)\n",
    "y=y.long()\n",
    "#绘图展示\n",
    "#plt.show()\n",
    "\n",
    "print('------      搭建网络      ------')\n",
    "#使用固定的方式继承并重写 init和forword两个类\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self,in_dim,n_hidden_1,n_hidden_2,n_hidden_3,out_dim):\n",
    "        #初始网络的内部结构\n",
    "        super(Net,self).__init__()\n",
    "        self.layer1=nn.Sequential(nn.Linear(in_dim,n_hidden_1),nn.BatchNorm1d(n_hidden_1),nn.ReLU(True))\n",
    "        self.layer2=nn.Sequential(nn.Linear(n_hidden_1,n_hidden_2),nn.BatchNorm1d(n_hidden_2),nn.ReLU(True))\n",
    "        self.layer3=nn.Sequential(nn.Linear(n_hidden_2,n_hidden_3),nn.BatchNorm1d(n_hidden_3),nn.ReLU(True))\n",
    "        self.layer4=nn.Linear(n_hidden_3,out_dim)\n",
    "    def forward(self, x):\n",
    "        #一次正向行走过程\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "        out=F.log_softmax(x,dim=1)\n",
    "        return out\n",
    "\n",
    "net=Net(in_dim=98,n_hidden_1=512,n_hidden_2=256,n_hidden_3=128,out_dim=40)\n",
    "print('网络结构为：',net)\n",
    "\n",
    "print('------      启动训练      ------')\n",
    "loss_func=F.nll_loss\n",
    "optimizer=torch.optim.SGD(net.parameters(),lr=0.01)\n",
    "\n",
    "#使用数据 进行正向训练，并对Variable变量进行反向梯度传播  启动1000次训练\n",
    "for t in range(1000):\n",
    "    #使用全量数据 进行正向行走\n",
    "    prediction=net(x)\n",
    "    loss=loss_func(prediction,y)\n",
    "    optimizer.zero_grad()  #清除上一梯度\n",
    "    loss.backward() #反向传播计算梯度\n",
    "    optimizer.step()  #应用梯度\n",
    "\n",
    "    #间隔一段，对训练过程进行可视化展示\n",
    "    if t%100==0:\n",
    "        print(loss.item())\n",
    "print(\"训练结束\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = Variable(x_test), Variable(y_test)\n",
    "y_test=y_test.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3159, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output=net(x_test)\n",
    "loss_func_t=F.nll_loss\n",
    "loss_t=loss_func_t(output,y_test)\n",
    "print(loss_t)\n",
    "pred=output.data.max(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  1,  1,  2,  2,  3,  3,  4, 17,  5,  5,  6,  6,  7,  7,  8,  8,\n",
       "         9,  9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 17,\n",
       "        18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23, 24, 24, 25, 25, 26, 26,\n",
       "        27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 32, 32, 33, 33, 39, 34, 35, 35,\n",
       "        36, 36, 37, 37, 38, 38, 39, 39])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,  8,\n",
       "         9,  9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 17,\n",
       "        18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23, 24, 24, 25, 25, 26, 26,\n",
       "        27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 32, 32, 33, 33, 34, 34, 35, 35,\n",
       "        36, 36, 37, 37, 38, 38, 39, 39])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=pred.numpy()\n",
    "label=y_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率97.50%\n"
     ]
    }
   ],
   "source": [
    "print(\"准确率%.2f%%\" % ((p==label).mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练集50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random,os,cv2,glob\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "from cv2 import cv2\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "def loadImageSet(folder=u'face', sampleCount=5): \n",
    "    trainData = []; testData = [];yTrain2=[];yTest2=[]\n",
    "    for k in range(40):\n",
    "        yTrain1 = [k]\n",
    "        yTest1 =[k]\n",
    "        folder2 = os.path.join(folder, 's%d' % (k+1))\n",
    "        data = [ cv2.imread(d,0) for d in glob.glob(os.path.join(folder2, '*.bmp'))]\n",
    "\n",
    "        # sample=[3,4,5,6]\n",
    "        sample=[5,6,7,8,9]\n",
    "        trainData.extend([data[i].ravel() for i in range(10) if i in sample])\n",
    "        testData.extend([data[i].ravel() for i in range(10) if i not in sample])\n",
    "\n",
    "  \n",
    "        yTrain = np.matrix(yTrain1)\n",
    "        yTrain= np.tile(yTrain1,5)\n",
    "        yTest=np.tile(yTest1,5)\n",
    "        yTrain2.extend(yTrain)\n",
    "        yTest2.extend(yTest)\n",
    "    return np.array(trainData),  np.array(yTrain2), np.array(testData), np.array(yTest2)\n",
    "\n",
    "xTrain_, yTrain, xTest_, yTest = loadImageSet()\n",
    "pca=PCA(n_components=0.9)\n",
    "xTrain_pca=pca.fit_transform(xTrain_)# 把原始训练集映射到主成分组成的子空间中\n",
    "xTest_pca=pca.transform(xTest_)# 把原始测试集映射到主成分组成的子空间中\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 77)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "D:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "D:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "D:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------      构建数据集      ------\n",
      "------      搭建网络      ------\n",
      "网络结构为： Net(\n",
      "  (layer1): Sequential(\n",
      "    (0): Linear(in_features=77, out_features=512, bias=True)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer4): Linear(in_features=128, out_features=40, bias=True)\n",
      ")\n",
      "------      启动训练      ------\n",
      "3.79097056388855\n",
      "1.239098310470581\n",
      "0.5833643078804016\n",
      "0.32094806432724\n",
      "0.20493127405643463\n",
      "0.14578235149383545\n",
      "0.11127085983753204\n",
      "0.08912692964076996\n",
      "0.07386768609285355\n",
      "0.06280512362718582\n",
      "训练结束\n",
      "tensor(0.4845, grad_fn=<NllLossBackward>)\n",
      "准确率97.50%\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.from_numpy(xTrain_pca)\n",
    "x_test=torch.from_numpy(xTest_pca)\n",
    "y_train=torch.from_numpy(yTrain)\n",
    "y_test=torch.from_numpy(yTest)\n",
    "\n",
    "\n",
    "x_train= torch.tensor(x_train, dtype=torch.float32)\n",
    "x_test= torch.tensor(x_test, dtype=torch.float32)\n",
    "y_train= torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test= torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "print('------      构建数据集      ------')\n",
    "# Variable是将tensor封装了下，用于自动求导使用\n",
    "x, y = Variable(x_train), Variable(y_train)\n",
    "y=y.long()\n",
    "#绘图展示\n",
    "#plt.show()\n",
    "print('------      搭建网络      ------')\n",
    "#使用固定的方式继承并重写 init和forword两个类\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self,in_dim,n_hidden_1,n_hidden_2,n_hidden_3,out_dim):\n",
    "        #初始网络的内部结构\n",
    "        super(Net,self).__init__()\n",
    "        self.layer1=nn.Sequential(nn.Linear(in_dim,n_hidden_1),nn.BatchNorm1d(n_hidden_1),nn.ReLU(True))\n",
    "        self.layer2=nn.Sequential(nn.Linear(n_hidden_1,n_hidden_2),nn.BatchNorm1d(n_hidden_2),nn.ReLU(True))\n",
    "        self.layer3=nn.Sequential(nn.Linear(n_hidden_2,n_hidden_3),nn.BatchNorm1d(n_hidden_3),nn.ReLU(True))\n",
    "        self.layer4=nn.Linear(n_hidden_3,out_dim)\n",
    "    def forward(self, x):\n",
    "        #一次正向行走过程\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "        out=F.log_softmax(x,dim=1)\n",
    "        return out\n",
    "\n",
    "net=Net(in_dim=77,n_hidden_1=512,n_hidden_2=256,n_hidden_3=128,out_dim=40)\n",
    "print('网络结构为：',net)\n",
    "\n",
    "print('------      启动训练      ------')\n",
    "loss_func=F.nll_loss\n",
    "optimizer=torch.optim.SGD(net.parameters(),lr=0.01)\n",
    "\n",
    "#使用数据 进行正向训练，并对Variable变量进行反向梯度传播  启动1000次训练\n",
    "for t in range(1000):\n",
    "    #使用全量数据 进行正向行走\n",
    "    prediction=net(x)\n",
    "    loss=loss_func(prediction,y)\n",
    "    optimizer.zero_grad()  #清除上一梯度\n",
    "    loss.backward() #反向传播计算梯度\n",
    "    optimizer.step()  #应用梯度\n",
    "\n",
    "    #间隔一段，对训练过程进行可视化展示\n",
    "    if t%100==0:\n",
    "        print(loss.item())\n",
    "print(\"训练结束\")\n",
    "\n",
    "x_test, y_test = Variable(x_test), Variable(y_test)\n",
    "y_test=y_test.long()\n",
    "\n",
    "output=net(x_test)\n",
    "loss_func_t=F.nll_loss\n",
    "loss_t=loss_func_t(output,y_test)\n",
    "print(loss_t)\n",
    "pred=output.data.max(1)[1]\n",
    "\n",
    "p=pred.numpy()\n",
    "label=y_test.numpy()\n",
    "print(\"准确率%.2f%%\" % ((p==label).mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测标签： [ 0  0  0  0  0  1  1  1  1  1  2  2  2  2  2  3  3  3  3  3  4 39  4  4\n",
      "  4  5  5  5  5  5  6  6  6  6  6  7  7  7  7  7  8  8  8  8  8  9  9  9\n",
      "  9  9 10 10 10 10 10 11 11 11 11 11 12 12 12 39 12 13 13 13 13 13 14 14\n",
      " 14 14 14 15 15 15 15 15 16 16 16  2 31 17 17 17 17 17 18 18 18 18 18 19\n",
      " 19 19 19 19 20 20 20 20 20 21 21 21 21 21 22 22 22 22 22 23 23 23 23 23\n",
      " 24 24 24 24 24 25 25 25 25 25 26 26 26 26 26 27 27 27 27 27 28 28 28 28\n",
      " 28 29 29 29 29 29 30 30 30 30 30 31 31 31 31 31 32 32 32 32 32 33 33 33\n",
      " 33 33 20 34 34 34 34 35 35 35 35 35 36 36 36 36 36 37 37 37 37 37 38 38\n",
      " 38 38 38 39 39 39 39 39]\n",
      "真实标签： [ 0  0  0  0  0  1  1  1  1  1  2  2  2  2  2  3  3  3  3  3  4  4  4  4\n",
      "  4  5  5  5  5  5  6  6  6  6  6  7  7  7  7  7  8  8  8  8  8  9  9  9\n",
      "  9  9 10 10 10 10 10 11 11 11 11 11 12 12 12 12 12 13 13 13 13 13 14 14\n",
      " 14 14 14 15 15 15 15 15 16 16 16 16 16 17 17 17 17 17 18 18 18 18 18 19\n",
      " 19 19 19 19 20 20 20 20 20 21 21 21 21 21 22 22 22 22 22 23 23 23 23 23\n",
      " 24 24 24 24 24 25 25 25 25 25 26 26 26 26 26 27 27 27 27 27 28 28 28 28\n",
      " 28 29 29 29 29 29 30 30 30 30 30 31 31 31 31 31 32 32 32 32 32 33 33 33\n",
      " 33 33 34 34 34 34 34 35 35 35 35 35 36 36 36 36 36 37 37 37 37 37 38 38\n",
      " 38 38 38 39 39 39 39 39]\n",
      "准确率97.50%\n"
     ]
    }
   ],
   "source": [
    "print(\"预测标签：\",p)\n",
    "print(\"真实标签：\",label)\n",
    "print(\"准确率%.2f%%\" % ((p==label).mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
